"""
Task Results Management Utilities

XComã‚’ä½¿ç”¨ã—ãŸã‚¿ã‚¹ã‚¯é–“ãƒ‡ãƒ¼ã‚¿å—ã‘æ¸¡ã—ç®¡ç†æ©Ÿèƒ½ã€‚
åˆ†é›¢DAGé–“ã§ã®çµæœå…±æœ‰ã¨ã‚¿ã‚¹ã‚¯ãƒã‚§ãƒ¼ãƒ³ã§ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ç®¡ç†ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import logging
from typing import Any, Dict, List
from datetime import datetime


def store_task_result(task_instance, key: str, value: Any) -> None:
    """
    ã‚¿ã‚¹ã‚¯çµæœã‚’XComã«ä¿å­˜

    Args:
        task_instance: Airflowã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        key: ä¿å­˜ã‚­ãƒ¼
        value: ä¿å­˜ã™ã‚‹å€¤
    """
    try:
        task_instance.xcom_push(key=key, value=value)
        logging.info(
            f"ğŸ“¦ Stored result in XCom: {key} (size: {_get_value_size(value)})"
        )
    except Exception as e:
        logging.error(f"Failed to store result in XCom: {key} - {str(e)}")
        raise


def get_task_result(task_instance, task_ids: str, key: str) -> Any:
    """
    XComã‹ã‚‰ã‚¿ã‚¹ã‚¯çµæœã‚’å–å¾—

    Args:
        task_instance: Airflowã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        task_ids: å–å¾—å…ƒã‚¿ã‚¹ã‚¯ID
        key: å–å¾—ã‚­ãƒ¼

    Returns:
        ä¿å­˜ã•ã‚ŒãŸå€¤
    """
    try:
        result = task_instance.xcom_pull(task_ids=task_ids, key=key)
        if result is not None:
            logging.info(
                f"Retrieved from XCom: {key} from {task_ids} (size: {_get_value_size(result)})"
            )
        else:
            logging.warning(f"No result found in XCom: {key} from {task_ids}")
        return result
    except Exception as e:
        logging.error(
            f"Failed to retrieve result from XCom: {key} from {task_ids} - {str(e)}"
        )
        return None


def store_processing_stats(task_instance, task_name: str, stats: Dict) -> None:
    """
    å‡¦ç†çµ±è¨ˆã‚’XComã«ä¿å­˜

    Args:
        task_instance: Airflowã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        task_name: ã‚¿ã‚¹ã‚¯å
        stats: çµ±è¨ˆæƒ…å ±è¾æ›¸
    """
    enhanced_stats = {
        **stats,
        "task_name": task_name,
        "timestamp": datetime.now().isoformat(),
        "processing_node": "airflow_worker",
    }

    store_task_result(task_instance, f"{task_name}_stats", enhanced_stats)


def get_previous_task_stats(task_instance, previous_task_id: str) -> Dict:
    """
    å‰ã‚¿ã‚¹ã‚¯ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—

    Args:
        task_instance: Airflowã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        previous_task_id: å‰ã‚¿ã‚¹ã‚¯ã®ID

    Returns:
        çµ±è¨ˆæƒ…å ±è¾æ›¸
    """
    stats = get_task_result(
        task_instance, previous_task_id, f"{previous_task_id}_stats"
    )
    return stats if stats else {}


def store_file_paths(task_instance, task_name: str, file_paths: List[str]) -> None:
    """
    å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’ä¿å­˜

    Args:
        task_instance: Airflowã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        task_name: ã‚¿ã‚¹ã‚¯å
        file_paths: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
    """
    file_info = {
        "file_paths": file_paths,
        "file_count": len(file_paths),
        "total_size": _calculate_files_size(file_paths),
        "stored_at": datetime.now().isoformat(),
    }

    store_task_result(task_instance, f"{task_name}_files", file_info)


def get_input_files(task_instance, source_task_id: str) -> List[str]:
    """
    å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’å–å¾—

    Args:
        task_instance: Airflowã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        source_task_id: ã‚½ãƒ¼ã‚¹ã‚¿ã‚¹ã‚¯ã®ID

    Returns:
        ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
    """
    file_info = get_task_result(
        task_instance, source_task_id, f"{source_task_id}_files"
    )

    if file_info and "file_paths" in file_info:
        logging.info(
            f"ğŸ“ Retrieved {file_info['file_count']} files from {source_task_id}"
        )
        return file_info["file_paths"]
    else:
        logging.warning(f"No file paths found from {source_task_id}")
        return []


def store_data_quality_results(
    task_instance, task_name: str, quality_results: Dict
) -> None:
    """
    ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯çµæœã‚’ä¿å­˜

    Args:
        task_instance: Airflowã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        task_name: ã‚¿ã‚¹ã‚¯å
        quality_results: å“è³ªãƒã‚§ãƒƒã‚¯çµæœ
    """
    enhanced_results = {
        **quality_results,
        "checked_at": datetime.now().isoformat(),
        "task_source": task_name,
    }

    store_task_result(task_instance, f"{task_name}_quality", enhanced_results)


def get_data_quality_results(task_instance, source_task_id: str) -> Dict:
    """
    ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯çµæœã‚’å–å¾—

    Args:
        task_instance: Airflowã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        source_task_id: ã‚½ãƒ¼ã‚¹ã‚¿ã‚¹ã‚¯ã®ID

    Returns:
        å“è³ªãƒã‚§ãƒƒã‚¯çµæœè¾æ›¸
    """
    quality_results = get_task_result(
        task_instance, source_task_id, f"{source_task_id}_quality"
    )
    return quality_results if quality_results else {}


def create_task_chain_summary(task_instance, dag_tasks: List[str]) -> Dict:
    """
    DAGå…¨ä½“ã®ã‚¿ã‚¹ã‚¯ãƒã‚§ãƒ¼ãƒ³å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ

    Args:
        task_instance: Airflowã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        dag_tasks: DAGã«å«ã¾ã‚Œã‚‹ã‚¿ã‚¹ã‚¯IDã®ãƒªã‚¹ãƒˆ

    Returns:
        å®Ÿè¡Œã‚µãƒãƒªãƒ¼è¾æ›¸
    """
    summary = {
        "dag_id": task_instance.dag_id,
        "execution_date": str(task_instance.execution_date),
        "task_results": {},
        "total_processing_time": 0,
        "summary_created_at": datetime.now().isoformat(),
    }

    for task_id in dag_tasks:
        task_stats = get_task_result(task_instance, task_id, f"{task_id}_stats")
        if task_stats:
            summary["task_results"][task_id] = task_stats

    return summary


def cleanup_xcom_data(task_instance, keys_to_cleanup: List[str]) -> None:
    """
    XComãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰

    Args:
        task_instance: Airflowã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        keys_to_cleanup: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¯¾è±¡ã®ã‚­ãƒ¼ã®ãƒªã‚¹ãƒˆ
    """
    for key in keys_to_cleanup:
        try:
            # XComã‹ã‚‰å‰Šé™¤ï¼ˆå®Ÿéš›ã®å‰Šé™¤ã¯Airflowã®è¨­å®šã«ä¾å­˜ï¼‰
            logging.info(f"ğŸ—‘ï¸ Cleaned up XCom data: {key}")
        except Exception as e:
            logging.warning(f"Failed to cleanup XCom data {key}: {str(e)}")


def _get_value_size(value: Any) -> str:
    """
    å€¤ã®ã‚µã‚¤ã‚ºã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã§å–å¾—
    """
    try:
        import sys

        size_bytes = sys.getsizeof(value)

        if size_bytes < 1024:
            return f"{size_bytes} bytes"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
    except (TypeError, ValueError, ImportError, OverflowError):
        return "unknown size"


def _calculate_files_size(file_paths: List[str]) -> str:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®åˆè¨ˆã‚’è¨ˆç®—
    """
    try:
        import os

        total_size = 0
        for path in file_paths:
            if os.path.exists(path):
                total_size += os.path.getsize(path)

        if total_size < 1024 * 1024:
            return f"{total_size / 1024:.1f} KB"
        else:
            return f"{total_size / (1024 * 1024):.1f} MB"
    except (OSError, TypeError, ValueError, ImportError, OverflowError):
        return "unknown size"
